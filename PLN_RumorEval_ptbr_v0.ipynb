{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Logo_Unifor](https://user-images.githubusercontent.com/61051085/81343928-3ce9d500-908c-11ea-9850-0210b4e94ba0.jpg)\n",
    "# PROJETO 01: Classificador de Grau de Confiabilidade em Tweets \n",
    "### Testes de modelos de linguagem tradicionais/neurais com Python \n",
    "    Disciplina: D322 - Tópicos Avançados em Processamento de Linguagem Natural | Professora Vládia\n",
    "    \n",
    "    Componentes da Equipe:\n",
    "    Antonio Marcos Aires Barbosa            | Matrícula: 2016397    marcosaires1@gmail.com\n",
    "    Ana Carla Guimaraes Aragao T Cavalcante | Matrícula: 2016403    carllasiga@gmail.com\n",
    "    Virginia Madeira Barros de Queiroz      | Matrícula: 2026537    virginiaqueiroz@edu.unifor.br"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contextualização:\n",
    "Definir o quanto uma determinada informação contida em mídias digitais é confiável ou não é um fator de elevada importância dado o grau de polaridade em que vivemos hoje, onde há literalmente uma briga de torcidas generalizada ao redor de todos assuntos da atualidade. \n",
    "\n",
    "Partimos da percepção de três fenômenos atuais que contribuem mais e mais para polarização inútil e prejudicial a qualquer debate sério:\n",
    "\n",
    "    1- Por um lado temos grandes veículos de comunicação em massa que, claramente, são praticantes de um tipo de jornalismo de opinião, onde não buscam expor dois lados de qualquer fato, muito pelo contrário, é claramente perceptível a utilização de toda e qualquer notícia para apoiar somente um lado político, conforme a conveniência de momento do veículo.\n",
    "    \n",
    "    2- Por outro outro lado temos vários indivíduos, criadores e difusores de coteúdos com informações infundadas, quando não absurdas, sem embasamento científico algum, talvez seduzidos pela atração de cliques fáceis, seguidores, compartihamentos e likes em diversas plataformas digitais. \n",
    "    \n",
    "    3- Temos ainda indivíduos que em meio ao fogo cruzado da guerra de opiniões infundadas, talvez movidos pela fuga do conflito preferem fugir dos embates, ora vestindo o manto dos \"isentões\" e apoiando argumentos falsos sem perceber, ora buscando fugir de toda e qualquer polêmica, o que poderia ser algo bom, caso não afastasse essas pessoas da busca por informações qualificadas, consequentemente afastando-as da verdade, seja ela qual for.\n",
    "    \n",
    "Seja ao ficar mudo em cima do muro, ou simplesmente abraçar cegamente um dos lados nessa guerra de torcidas (fenômeno muito parecido ao que ocorre nos esportes de massa, onde só as paixões e sentimentos irracionais definem qual lado o indivíduo escolhe) nos parece que, cada vez mais, perde-se espaço para o bom debate, praticamente já não há onde conversarmos sem ofensas, sem milindres, e sem emotividades exarcebadas. Buscamos gerar uma ferramenta que forneça oportunidade para o contraditório e troca de bons argumentos pautados em racionalidade, com passionalidade controlada e limitada a níveis minimamente civilizados de respeito à opinião contrária. Muito diferente da seita de \"FakeNews\" que promove o cancelamento de tudo e de todos que não lhe pareça conveniente, sob o manto de uma \"verdade abosoluta\" é geralmente falaciosa.\n",
    "\n",
    "Realizamos este trabalho de pesquisa durante as disciplinas de Argumentos Formais em Computação e de Processamento de linguagem Natural no Programa de Pós-Graduação em Informática Aplicada da Universidade de Fortaleza - UNIFOR. Acreditamos que somente pautados pela busca sincera da Verdade, entre erros sinceros e acertos temporários, é que podemos avançar em nossa vida pessoal e no convívio social, pautados na verdade mais plausível até o momento. Cientes da impossibilidade prática da ausência de paixões, ou mesmo de isenção completa, já que nossas opiniões não podem ser mais que a soma de opiniões alheias e anteriores a nós mesmos, por mais que não gostemos disso, mesmo para aqueles que juram serem \"livres pensadores\" é impossível para qualquer ser vivente ser completamente original em suas ideias, e muito fácil de sua ignorância ser maior que seu alcance de conhecimentos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objetivo:\n",
    "Criar um modelo de Machine Learning capaz de receber, tratar e avaliar cada uma de suas sentenças quanto à validade de sua argumentação lógica. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Projetos e suas fontes de dados:**\n",
    "    \n",
    "    Projeto 01: Classificação de rumores em português\n",
    "        Corpus utilizado: Tweets agrupados no projeto FakeTweet.BR (português) (https://github.com/prc992/FakeTweet.Br) e \n",
    "    \n",
    "    Projeto 02: Classificação de rumores em inglês\n",
    "        Corpus utilizado: Tweets agrupados no projeto RumourEval 2019 (inglês)(https://figshare.com/articles/RumourEval_2019_data/8845580)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fase01. Ingestão, Organização, Leitura do corpus em português do Brasil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import re    \n",
    "import nltk   \n",
    "import string \n",
    "import warnings \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt  \n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", 200) \n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FakeTweetBr-Test.csv\n",
      "FakeTweetBr.csv\n"
     ]
    }
   ],
   "source": [
    "# Definir um caminho específico na estrutura de diretório\n",
    "path = \"datasets\"\n",
    "dirs = os.listdir(path)\n",
    "\n",
    "# Listar arquivos do caminho específico\n",
    "for file in dirs:\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>subject</th>\n",
       "      <th>text</th>\n",
       "      <th>classificacao</th>\n",
       "      <th>date</th>\n",
       "      <th>retweets</th>\n",
       "      <th>favorites</th>\n",
       "      <th>permalink</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.124513e+18</td>\n",
       "      <td>macaco marielle</td>\n",
       "      <td>Marielle &gt;BANDIDOS Narco-traficantes-Milícias pisou na bola PCC &gt;Mandante do crime #Brazão do PT #OrganizaçãoCriminosa Assassinada por THIAGO- MACACO Midia para de acusar quem destruiu a sonhada #...</td>\n",
       "      <td>fake</td>\n",
       "      <td>2019-05-04 0:16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://twitter.com/MRTT_/status/1124513050218893312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.124049e+18</td>\n",
       "      <td>macaco marielle</td>\n",
       "      <td>Bem, as últimas noticias a respeito disso que o verdadeiro assassino de Marielle não é aqueles acusados senão um elemento de codinome  Macaco \". Ou seja, não colou a relação Bolsonaro x Marielle ....</td>\n",
       "      <td>fake</td>\n",
       "      <td>2019-05-02 17:33</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://twitter.com/EvaristoKlebber/status/1124049371006476293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>1.119295e+18</td>\n",
       "      <td>macaco marielle</td>\n",
       "      <td>@jornalnacional convivi com notícias da Marielle durante 3 meses quase todos os dias. Porque pararam as reportagens? Só porque se descobriu que seu matador foi Thiago macaco ? Negro favelado e lig...</td>\n",
       "      <td>fake</td>\n",
       "      <td>2019-04-19 14:41</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://twitter.com/luiztemper/status/1119295029204398080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>1.114583e+18</td>\n",
       "      <td>macaco marielle</td>\n",
       "      <td>O Cesari Battisti confessou seus crimes, a esquerda calou; o assassino de MARIELLE foi descoberto, a esquerda se calou e agora o Luladrão confessou, a esquerda meteu a língua onde o macaco meu o c...</td>\n",
       "      <td>fake</td>\n",
       "      <td>2019-04-06 14:36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://twitter.com/GrimoaldoL/status/1114582545625227333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>1.113246e+18</td>\n",
       "      <td>macaco marielle</td>\n",
       "      <td>[Agência Lupa] Verificamos: É falso que Thiago Macaco foi identificado como assassino de Marielle https:// piaui.folha.uol.com.br/lupa/2019/04/0 1/verificamos-marielle-preso-thiago/ …</td>\n",
       "      <td>true</td>\n",
       "      <td>2019-04-02 22:04</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>https://twitter.com/antmarobel/status/1113245911591862272</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0            id          subject  \\\n",
       "0           0  1.124513e+18  macaco marielle   \n",
       "1           1  1.124049e+18  macaco marielle   \n",
       "2           5  1.119295e+18  macaco marielle   \n",
       "3          10  1.114583e+18  macaco marielle   \n",
       "4          11  1.113246e+18  macaco marielle   \n",
       "\n",
       "                                                                                                                                                                                                      text  \\\n",
       "0  Marielle >BANDIDOS Narco-traficantes-Milícias pisou na bola PCC >Mandante do crime #Brazão do PT #OrganizaçãoCriminosa Assassinada por THIAGO- MACACO Midia para de acusar quem destruiu a sonhada #...   \n",
       "1  Bem, as últimas noticias a respeito disso que o verdadeiro assassino de Marielle não é aqueles acusados senão um elemento de codinome  Macaco \". Ou seja, não colou a relação Bolsonaro x Marielle ....   \n",
       "2  @jornalnacional convivi com notícias da Marielle durante 3 meses quase todos os dias. Porque pararam as reportagens? Só porque se descobriu que seu matador foi Thiago macaco ? Negro favelado e lig...   \n",
       "3  O Cesari Battisti confessou seus crimes, a esquerda calou; o assassino de MARIELLE foi descoberto, a esquerda se calou e agora o Luladrão confessou, a esquerda meteu a língua onde o macaco meu o c...   \n",
       "4                  [Agência Lupa] Verificamos: É falso que Thiago Macaco foi identificado como assassino de Marielle https:// piaui.folha.uol.com.br/lupa/2019/04/0 1/verificamos-marielle-preso-thiago/ …   \n",
       "\n",
       "  classificacao              date  retweets  favorites  \\\n",
       "0          fake   2019-05-04 0:16         0          0   \n",
       "1          fake  2019-05-02 17:33         0          0   \n",
       "2          fake  2019-04-19 14:41         0          0   \n",
       "3          fake  2019-04-06 14:36         0          0   \n",
       "4          true  2019-04-02 22:04         1          0   \n",
       "\n",
       "                                                        permalink  \n",
       "0            https://twitter.com/MRTT_/status/1124513050218893312  \n",
       "1  https://twitter.com/EvaristoKlebber/status/1124049371006476293  \n",
       "2       https://twitter.com/luiztemper/status/1119295029204398080  \n",
       "3       https://twitter.com/GrimoaldoL/status/1114582545625227333  \n",
       "4       https://twitter.com/antmarobel/status/1113245911591862272  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## lê entrada como um csv separado por tabulações '\\t' e armazena em um DataFrame\n",
    "strFile = path + \"/\" + \"FakeTweetBr.csv\"\n",
    "df00_traintest = pd.read_csv(strFile)\n",
    "df00_traintest.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fake    188\n",
       "true     91\n",
       "Name: classificacao, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df00_traintest['classificacao'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#sentences = \"Sentence: \" + df_train['texto-pre'].values + \" Reply: \" + df_train['reply'].values\n",
    "sentences =  df00_traintest['text'].values\n",
    "y = df00_traintest['classificacao'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_train, sentences_test, y_train, y_test = train_test_split(sentences, y, test_size=0.1, random_state=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 2))\n",
    "vectorizer.fit(sentences_train)\n",
    "\n",
    "X_train = vectorizer.transform(sentences_train)\n",
    "X_test  = vectorizer.transform(sentences_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transforma_vetor_str_int(vetor):\n",
    "    vetor_retorno = []\n",
    "    \n",
    "    for i in range(0, len(vetor)): \n",
    "        \n",
    "        if vetor[i] == 'fake':\n",
    "            vetor_retorno.append(1)\n",
    "        else: \n",
    "            vetor_retorno.append(2)\n",
    "    return vetor_retorno\n",
    "\n",
    "def transforma_vetor_int_str(vetor):\n",
    "    vetor_retorno = []\n",
    "  \n",
    "    for i in range(0, len(vetor)): \n",
    "        if vetor[i] == 1:\n",
    "            vetor_retorno.append('fake')\n",
    "            \n",
    "        if vetor[i] == 2:\n",
    "            vetor_retorno.append('true')\n",
    " \n",
    "    return vetor_retorno    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train2 = transforma_vetor_str_int(y_train)\n",
    "y_test2 = transforma_vetor_str_int(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((251, 7407), 251)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape,len(y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  10 out of  10 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   7 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  10 out of  10 | elapsed:    0.9s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  10 out of  10 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "from sklearn.naive_bayes import BaseNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "from sklearn.ensemble  import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "cvC = 10\n",
    "classifier = LogisticRegression()\n",
    "pred = cross_val_predict(classifier, X_train, y_train2, cv=cvC, verbose=True, n_jobs=2)\n",
    "\n",
    "classifier2 = SGDClassifier()\n",
    "pred2 = cross_val_predict(classifier2, X_train, y_train2, cv=cvC, verbose=True, n_jobs=2)\n",
    "\n",
    "classifier3 = BernoulliNB()\n",
    "pred3 = cross_val_predict(classifier3, X_train, y_train2, cv=cvC, verbose=True, n_jobs=2)\n",
    "\n",
    "classifier4 = RandomForestClassifier()\n",
    "pred4 = cross_val_predict(classifier4, X_train, y_train2, cv=cvC, verbose=True, n_jobs=2)\n",
    "\n",
    "classifier5 = LinearSVC()\n",
    "pred5 = cross_val_predict(classifier5, X_train, y_train2, cv=cvC, verbose=True, n_jobs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score,precision_score,recall_score\n",
    "\n",
    "score = accuracy_score(y_train2, pred)\n",
    "score2 = accuracy_score(y_train2, pred2)\n",
    "score3 = accuracy_score(y_train2, pred3)\n",
    "score4 = accuracy_score(y_train2, pred4)\n",
    "score5 = accuracy_score(y_train2, pred5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps1 = precision_score(y_train2, pred, average = 'macro')\n",
    "r1  = recall_score(y_train2, pred, average = 'macro') \n",
    "\n",
    "ps2 = precision_score(y_train2, pred2, average = 'macro')\n",
    "r2 = recall_score(y_train2, pred2, average = 'macro') \n",
    "\n",
    "ps3 = precision_score(y_train2, pred3, average = 'macro')\n",
    "r3  = recall_score(y_train2, pred3, average = 'macro') \n",
    "\n",
    "ps4 = precision_score(y_train2, pred4, average = 'macro')\n",
    "r4  = recall_score(y_train2, pred4, average = 'macro') \n",
    "\n",
    "ps5 = precision_score(y_train2, pred5, average = 'macro')\n",
    "r5  = recall_score(y_train2, pred5, average = 'macro') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_geral = f1_score(y_train2, pred, average = 'macro')\n",
    "f1_geral2 = f1_score(y_train2, pred2, average = 'macro')\n",
    "f1_geral3 = f1_score(y_train2, pred3, average = 'macro')\n",
    "f1_geral4 = f1_score(y_train2, pred4, average = 'macro')\n",
    "f1_geral5 = f1_score(y_train2, pred5, average = 'macro')\n",
    "df1_geral = f1_score(y_train2, pred, average = None)\n",
    "df1_gera2 = f1_score(y_train2, pred2, average = None)\n",
    "df1_gera3 = f1_score(y_train2, pred3, average = None)\n",
    "df1_gera4 = f1_score(y_train2, pred4, average = None)\n",
    "df1_gera5 = f1_score(y_train2, pred5, average = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression \n",
      " Accuracy : 0.8565737051792829 \n",
      " F1_Score : 0.8184667309546769 \n",
      " Precision: 0.8883647798742138 \n",
      " Recall   : 0.792276247848537 \n",
      " F1-Classe: [0.90163934 0.73529412]\n",
      "------------------------------------------------------------------------------------------\n",
      "SGDClassifier \n",
      " Accuracy : 0.8884462151394422 \n",
      " F1_Score : 0.873995983935743 \n",
      " Precision: 0.873995983935743 \n",
      " Recall   : 0.873995983935743 \n",
      " F1-Classe: [0.91666667 0.8313253 ]\n",
      "------------------------------------------------------------------------------------------\n",
      "ComplementNB \n",
      " Accuracy : 0.7450199203187251 \n",
      " F1_Score : 0.6119056822574411 \n",
      " Precision: 0.8392339544513457 \n",
      " Recall   : 0.6175057372346529 \n",
      " F1-Classe: [0.83919598 0.38461538]\n",
      "------------------------------------------------------------------------------------------\n",
      "RandomForestClassifier \n",
      " Accuracy : 0.7928286852589641 \n",
      " F1_Score : 0.7152705061082024 \n",
      " Precision: 0.8449734781510483 \n",
      " Recall   : 0.6958907056798622 \n",
      " F1-Classe: [0.86387435 0.56666667]\n",
      "------------------------------------------------------------------------------------------\n",
      "SVM \n",
      " Accuracy : 0.8725099601593626 \n",
      " F1_Score : 0.8415153906866613 \n",
      " Precision: 0.8989419424850786 \n",
      " Recall   : 0.8163726333907056 \n",
      " F1-Classe: [0.91160221 0.77142857]\n"
     ]
    }
   ],
   "source": [
    "print(\"LogisticRegression\", \n",
    "      \"\\n Accuracy :\",score,\n",
    "      \"\\n F1_Score :\",f1_geral,\n",
    "      \"\\n Precision:\",ps1,\n",
    "      \"\\n Recall   :\",r1,\n",
    "      \"\\n F1-Classe:\",df1_geral)\n",
    "print(\"-\"*90)\n",
    "print(\"SGDClassifier\",\n",
    "      \"\\n Accuracy :\",score2,\n",
    "      \"\\n F1_Score :\",f1_geral2,\n",
    "      \"\\n Precision:\",ps2,\n",
    "      \"\\n Recall   :\",r2,\n",
    "      \"\\n F1-Classe:\",df1_gera2)\n",
    "print(\"-\"*90)\n",
    "print(\"ComplementNB\",\n",
    "      \"\\n Accuracy :\",score3,\n",
    "      \"\\n F1_Score :\",f1_geral3,\n",
    "      \"\\n Precision:\",ps3,\n",
    "      \"\\n Recall   :\",r3,\n",
    "      \"\\n F1-Classe:\",df1_gera3)\n",
    "print(\"-\"*90)\n",
    "print(\"RandomForestClassifier\",\n",
    "      \"\\n Accuracy :\",score4,\n",
    "      \"\\n F1_Score :\",f1_geral4,\n",
    "      \"\\n Precision:\",ps4,\n",
    "      \"\\n Recall   :\",r4,\n",
    "      \"\\n F1-Classe:\",df1_gera4)\n",
    "print(\"-\"*90)\n",
    "print(\"SVM\",\n",
    "      \"\\n Accuracy :\",score5,\n",
    "      \"\\n F1_Score :\",f1_geral5,\n",
    "      \"\\n Precision:\",ps5,\n",
    "      \"\\n Recall   :\",r5,  \n",
    "      \"\\n F1-Classe:\",df1_gera5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE \n",
    "sm = SMOTE(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_res, y_res = sm.fit_resample(X_train, y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_res\n",
    "y_train2 = y_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test2 = sm.fit_resample(X_test, y_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  10 out of  10 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   7 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  10 out of  10 | elapsed:    1.1s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  10 out of  10 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "cvC = 10\n",
    "classifier = LogisticRegression()\n",
    "pred = cross_val_predict(classifier, X_train, y_train2, cv=cvC, verbose=True, n_jobs=2)\n",
    "\n",
    "classifier2 = SGDClassifier()\n",
    "pred2 = cross_val_predict(classifier2, X_train, y_train2, cv=cvC, verbose=True, n_jobs=2)\n",
    "\n",
    "classifier3 = BernoulliNB()\n",
    "pred3 = cross_val_predict(classifier3, X_train, y_train2, cv=cvC, verbose=True, n_jobs=2)\n",
    "\n",
    "classifier4 = RandomForestClassifier()\n",
    "pred4 = cross_val_predict(classifier4, X_train, y_train2, cv=cvC, verbose=True, n_jobs=2)\n",
    "\n",
    "classifier5 = LinearSVC()\n",
    "pred5 = cross_val_predict(classifier5, X_train, y_train2, cv=cvC, verbose=True, n_jobs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import  f1_score, precision_score, recall_score\n",
    "acc1 = accuracy_score(y_train2, pred)\n",
    "acc2 = accuracy_score(y_train2, pred2)\n",
    "acc3 = accuracy_score(y_train2, pred3)\n",
    "acc4 = accuracy_score(y_train2, pred4)\n",
    "acc5 = accuracy_score(y_train2, pred5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps1 = precision_score(y_train2, pred, average = 'macro')\n",
    "r1  = recall_score(y_train2, pred, average = 'macro') \n",
    "\n",
    "ps2 = precision_score(y_train2, pred2, average = 'macro')\n",
    "r2 = recall_score(y_train2, pred2, average = 'macro') \n",
    "\n",
    "ps3 = precision_score(y_train2, pred3, average = 'macro')\n",
    "r3  = recall_score(y_train2, pred3, average = 'macro') \n",
    "\n",
    "ps4 = precision_score(y_train2, pred4, average = 'macro')\n",
    "r4  = recall_score(y_train2, pred4, average = 'macro') \n",
    "\n",
    "ps5 = precision_score(y_train2, pred5, average = 'macro')\n",
    "r5  = recall_score(y_train2, pred5, average = 'macro') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_geral = f1_score(y_train2, pred, average = 'macro')\n",
    "f1_gera2 = f1_score(y_train2, pred2, average = 'macro')\n",
    "f1_gera3 = f1_score(y_train2, pred3, average = 'macro')\n",
    "f1_gera4 = f1_score(y_train2, pred4, average = 'macro')\n",
    "f1_gera5 = f1_score(y_train2, pred5, average = 'macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_geral = f1_score(y_train2, pred, average = None)\n",
    "df1_gera2 = f1_score(y_train2, pred2, average = None)\n",
    "df1_gera3 = f1_score(y_train2, pred3, average = None)\n",
    "df1_gera4 = f1_score(y_train2, pred4, average = None)\n",
    "df1_gera5 = f1_score(y_train2, pred5, average = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression \n",
      " Accuracy: 0.8565737051792829 , F1_Score: 0.8533548289406881  Precision : 0.8621870357621653  Recall : 0.8541666666666667 \n",
      " F1-Classe [0.84244373 0.86426593]\n",
      "SGDClassifier \n",
      " Accuracy: 0.8884462151394422 , F1_Score: 0.873995983935743  Precision : 0.9019138755980861  Recall : 0.9017857142857143 \n",
      " F1-Classe [0.9009009  0.90265487]\n",
      "ComplementNB \n",
      " Accuracy: 0.7450199203187251 , F1_Score: 0.6119056822574411  Precision : 0.8146067415730337  Recall : 0.7053571428571428 \n",
      " F1-Classe [0.9009009  0.90265487]\n",
      "RandomForestClassifier \n",
      " Accuracy: 0.7928286852589641 , F1_Score:  Precision : 0.8216682464454976  Recall : 0.8005952380952381 \n",
      " F1-Classe [0.9009009  0.90265487]\n",
      "SVM \n",
      " Accuracy: 0.8725099601593626 , F1_Score: 0.8415153906866613  Precision : 0.8481641785570186  Recall : 0.8363095238095238 \n",
      " F1-Classe [0.9009009  0.90265487]\n"
     ]
    }
   ],
   "source": [
    "print(\"LogisticRegression\", \n",
    "      \"\\n Accuracy:\", score,\", F1_Score:\", f1_geral,\" Precision :\",ps1,\" Recall :\",r1,  \"\\n F1-Classe\",df1_geral)\n",
    "print(\"SGDClassifier\", \n",
    "      \"\\n Accuracy:\", score2,\", F1_Score:\", f1_geral2,\" Precision :\",ps2,\" Recall :\",r2,  \"\\n F1-Classe\",df1_gera2)\n",
    "print(\"ComplementNB\", \n",
    "      \"\\n Accuracy:\", score3,\", F1_Score:\", f1_geral3,\" Precision :\",ps3,\" Recall :\",r3,  \"\\n F1-Classe\",df1_gera2)\n",
    "print(\"RandomForestClassifier\", \n",
    "      \"\\n Accuracy:\", score4,\", F1_Score:\",\" Precision :\",ps4,\" Recall :\",r4,  \"\\n F1-Classe\",df1_gera2)\n",
    "print(\"SVM\", \n",
    "      \"\\n Accuracy:\", score5,\", F1_Score:\", f1_geral5,\" Precision :\",ps5,\" Recall :\",r5,  \"\\n F1-Classe\",df1_gera2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression \n",
      " Accuracy: 0.8541666666666666 , F1_Score: 0.8533548289406881 \n",
      " [0.84244373 0.86426593]\n",
      "SGDClassifier \n",
      " Accuracy: 0.9017857142857143 , F1_Score: 0.901777884078769 \n",
      " [0.9009009  0.90265487]\n",
      "ComplementNB \n",
      " Accuracy: 0.7053571428571429 , F1_Score: 0.6773461370580532 \n",
      " [0.58227848 0.77241379]\n",
      "RandomForestClassifier \n",
      " Accuracy: 0.8005952380952381 , F1_Score: 0.7972750276909777 \n",
      " [0.77133106 0.823219  ]\n",
      "SVM \n",
      " Accuracy: 0.8363095238095238 , F1_Score: 0.8349041854647787 \n",
      " [0.81967213 0.85013624]\n"
     ]
    }
   ],
   "source": [
    "print(\"LogisticRegression\", \n",
    "      \"\\n Accuracy:\", acc1,\", F1_Score:\", f1_geral, \"\\n\",df1_geral)\n",
    "print(\"SGDClassifier\", \n",
    "      \"\\n Accuracy:\", acc2,\", F1_Score:\", f1_gera2, \"\\n\",df1_gera2)\n",
    "print(\"ComplementNB\", \n",
    "      \"\\n Accuracy:\", acc3,\", F1_Score:\", f1_gera3, \"\\n\",df1_gera3)\n",
    "print(\"RandomForestClassifier\", \n",
    "      \"\\n Accuracy:\", acc4,\", F1_Score:\", f1_gera4, \"\\n\",df1_gera4)\n",
    "print(\"SVM\", \n",
    "      \"\\n Accuracy:\", acc5,\", F1_Score:\", f1_gera5, \"\\n\",df1_gera5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VALIDAÇÃO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "strFile = path + \"/\" + \"FakeTweetBr-Test.csv\"\n",
    "df_train = pd.read_csv(strFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fake    12\n",
       "TRUE     8\n",
       "Name: classificacao, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['classificacao'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "decreto oab obrigatoriedade      4\n",
       "banco brasil vetado bolsonaro    4\n",
       "prefeito rio nise silveira       3\n",
       "gustave notre dame               3\n",
       "navio msc lixo                   3\n",
       "nova york estupro prefeito       2\n",
       "atacadão cestas básicas          1\n",
       "Name: subject, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['subject'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences =  df_train['text'].values\n",
    "y = df_train['classificacao'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test2 = sm.fit_resample(X_test, y_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = vectorizer.transform(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val = transforma_vetor_str_int(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC()"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train, y_train2)\n",
    "\n",
    "classifier2 = SGDClassifier()\n",
    "classifier2.fit(X_train, y_train2)\n",
    "\n",
    "classifier3 = BernoulliNB()\n",
    "classifier3.fit(X_train, y_train2)\n",
    "\n",
    "classifier4 = RandomForestClassifier()\n",
    "classifier4.fit(X_train, y_train2)\n",
    "\n",
    "classifier5 = LinearSVC()\n",
    "classifier5.fit(X_train, y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = classifier.score(X_val, y_val)\n",
    "score2 = classifier2.score(X_val, y_val)\n",
    "score3 = classifier3.score(X_val, y_val)\n",
    "score4 = classifier4.score(X_val, y_val)\n",
    "score5 = classifier5.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import  f1_score, precision_score, recall_score\n",
    "\n",
    "y_predict_val = classifier.predict(X_val)\n",
    "y_predict_val2 = classifier2.predict(X_val)\n",
    "y_predict_val3 = classifier3.predict(X_val)\n",
    "y_predict_val4 = classifier4.predict(X_val)\n",
    "y_predict_val5 = classifier5.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marco\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "ps1 = precision_score(y_val, y_predict_val, average = 'macro')\n",
    "r1  = recall_score(y_val, y_predict_val, average = 'macro') \n",
    "ps2 = precision_score(y_val, y_predict_val2, average = 'macro')\n",
    "r2 = recall_score(y_val, y_predict_val2, average = 'macro') \n",
    "ps3 = precision_score(y_val, y_predict_val3, average = 'macro')\n",
    "r3  = recall_score(y_val, y_predict_val3, average = 'macro') \n",
    "\n",
    "ps4 = precision_score(y_val, y_predict_val4, average = 'macro')\n",
    "r4  = recall_score(y_val, y_predict_val4, average = 'macro') \n",
    "\n",
    "ps5 = precision_score(y_val, y_predict_val5, average = 'macro')\n",
    "r5  = recall_score(y_val, y_predict_val5, average = 'macro') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_geral = f1_score(y_val, y_predict_val, average = None)\n",
    "df1_gera2 = f1_score(y_val, y_predict_val2, average = None)\n",
    "df1_gera3 = f1_score(y_val, y_predict_val3, average = None)\n",
    "df1_gera4 = f1_score(y_val, y_predict_val4, average = None)\n",
    "df1_gera5 = f1_score(y_val, y_predict_val5, average = None)\n",
    "\n",
    "f1_geral = f1_score(y_val, y_predict_val, average = 'macro')\n",
    "f1_geral2 = f1_score(y_val, y_predict_val2, average = 'macro')\n",
    "f1_geral3 = f1_score(y_val, y_predict_val3, average = 'macro')\n",
    "f1_geral4 = f1_score(y_val, y_predict_val4, average = 'macro')\n",
    "f1_geral5 = f1_score(y_val, y_predict_val5, average = 'macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression \n",
      " Accuracy: 0.45 , F1_Score: 0.41333333333333333  Precision : 0.5392156862745098  Recall : 0.5208333333333334 \n",
      " F1-Classe [0.26666667 0.56      ]\n",
      "SGDClassifier \n",
      " Accuracy: 0.8 , F1_Score: 0.7916666666666667  Precision : 0.7916666666666667  Recall : 0.7916666666666667 \n",
      " F1-Classe [0.83333333 0.75      ]\n",
      "ComplementNB \n",
      " Accuracy: 0.4 , F1_Score: 0.28571428571428575  Precision : 0.2  Recall : 0.5 \n",
      " F1-Classe [0.         0.57142857]\n",
      "RandomForestClassifier \n",
      " Accuracy: 0.4 , F1_Score: 0.34065934065934067  Precision : 0.4444444444444444  Recall : 0.4791666666666667 \n",
      " F1-Classe [0.14285714 0.53846154]\n",
      "SVM \n",
      " Accuracy: 0.4 , F1_Score: 0.34065934065934067  Precision : 0.4444444444444444  Recall : 0.4791666666666667 \n",
      " F1-Classe [0.14285714 0.53846154]\n"
     ]
    }
   ],
   "source": [
    "print(\"LogisticRegression\", \n",
    "      \"\\n Accuracy:\", score,\", F1_Score:\", f1_geral,\" Precision :\",ps1,\" Recall :\",r1,  \"\\n F1-Classe\",df1_geral)\n",
    "print(\"SGDClassifier\", \n",
    "      \"\\n Accuracy:\", score2,\", F1_Score:\", f1_geral2,\" Precision :\",ps2,\" Recall :\",r2,  \"\\n F1-Classe\",df1_gera2)\n",
    "print(\"ComplementNB\", \n",
    "      \"\\n Accuracy:\", score3,\", F1_Score:\", f1_geral3,\" Precision :\",ps3,\" Recall :\",r3,  \"\\n F1-Classe\",df1_gera3)\n",
    "print(\"RandomForestClassifier\", \n",
    "      \"\\n Accuracy:\", score4,\", F1_Score:\",f1_geral4,\" Precision :\",ps4,\" Recall :\",r4,  \"\\n F1-Classe\",df1_gera4)\n",
    "print(\"SVM\", \n",
    "      \"\\n Accuracy:\", score5,\", F1_Score:\", f1_geral5,\" Precision :\",ps5,\" Recall :\",r5,  \"\\n F1-Classe\",df1_gera5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1, 11],\n",
       "       [ 1,  7]], dtype=int64)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_val, y_predict_val5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_actu = pd.Series(y_val, name='Actual')\n",
    "y_pred = pd.Series(y_predict_val5, name='Predicted')\n",
    "df_confusion = pd.crosstab(y_actu, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_conf_norm = df_confusion / df_confusion.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.083333</td>\n",
       "      <td>1.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted         1      2\n",
       "Actual                    \n",
       "1          0.083333  1.375\n",
       "2          0.083333  0.875"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_conf_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fase02. Pré-processamento dos corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Funções usadas para tratamento e limpeza dos dados de tweets\n",
    "\n",
    "def remove_contracao(origem, destino, column):            # Função para remover contrações\n",
    "    for x in range(1,len(column)):\n",
    "        return(re.sub(origem, destino, column))\n",
    "\n",
    "origem, destino = '',''\n",
    "linhas = []\n",
    "lst_contr = [('’re',' are'), \n",
    "             ('’s',' is'),\n",
    "             ('\\'s',' is'),\n",
    "             ('n’t',' not'),\n",
    "             ('don\\'t','do not'),\n",
    "             ('&amp; ',''),\n",
    "             ('\\'ve',' have '),\n",
    "             ('Taken\\\"',' taken'),\n",
    "             ('2u','to you'),\n",
    "             ('4u','for you'),\n",
    "             ('2U','to you'),\n",
    "             ('4U','for you')]\n",
    "\n",
    "lst_simbol = [('.'), ('?'), ('!'), ('%'), ('&'), ('*'), ('('), (')'), ('['), (']'), ('{'), ('}'), ('_'), ('-'), ('+'), ('='),\n",
    "             ('§'), ('$'), ('º'), ('°'), (':'), (';'), ('>'), ('<'), (','), ('“'), ('\\\"'), ('/'), ('#'), ('@'), ('-'),\n",
    "             ('0'),('1'),('2'),('3'),('4'),('5'),('6'),('7'),('8'),('9')]\n",
    "\n",
    "def remove_emoji(text):     # Função para remover emojis\n",
    "    allchars = [str for str in text]\n",
    "    emoji_list = [c for c in allchars if c in emoji.UNICODE_EMOJI]\n",
    "    clean_text = ' '.join([str for str in text.split() if not any(i in str for i in emoji_list)])\n",
    "    return clean_text\n",
    "\n",
    "def clean(text):           # Função para remover emojis, símbolos e números\n",
    "    allchars = [str for str in text]\n",
    "\n",
    "    emoji_list = [c for c in allchars if c in emoji.UNICODE_EMOJI]\n",
    "    clean_emoji= ' '.join([str for str in text.split() if not any(i in str for i in emoji_list)])\n",
    "    print('emojis a remover:', emoji_list)\n",
    "    \n",
    "    temp_text  = [str for str in clean_emoji]\n",
    "\n",
    "    simbol_list= [s for s in temp_text if s in lst_simbol] \n",
    "    print('símbolos a remover:', simbol_list,'\\n')\n",
    "    \n",
    "    clean_text = ''.join([str for str in temp_text if not any(i in str for i in simbol_list)])\n",
    "    return clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traintest = pd.read_csv('datasets/olid-training-v1.0.tsv', sep='\\t', usecols=('tweet','subtask_a','subtask_b','subtask_c'))\n",
    "traintest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# binarização dos targets\n",
    "import numpy as np\n",
    "off = 2\n",
    "dy = []\n",
    "for k in traintest['subtask_a']:\n",
    "#     print('Estado inicial:',k)\n",
    "    if k == 'OFF':\n",
    "        off = 1\n",
    "#         print('Setado para:   ',off,'\\n')\n",
    "        dy.append(off)\n",
    "    elif k == 'NOT':\n",
    "        off = 0\n",
    "#         print('Setado para:   ',off,'\\n')\n",
    "        dy.append(off)\n",
    "    else:\n",
    "        off= 2\n",
    "\n",
    "y = pd.Series(dy)\n",
    "\n",
    "df_dados = pd.concat([traintest['tweet'], traintest['subtask_a'], y], axis=1)\n",
    "df_dados.columns = ['tweet','subtask_a', 'target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Pré-processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import * \n",
    "import re\n",
    "\n",
    "def remove_pattern(input_txt, pattern):\n",
    "    r = re.findall(pattern, input_txt)\n",
    "    for i in r:\n",
    "        input_txt = re.sub(i, '', input_txt)\n",
    "    return input_txt\n",
    "\n",
    "def prepare(df):\n",
    "    df['tidy_tweet'] = np.vectorize(remove_pattern)(df['tweet'], \"@[\\w]*\") \n",
    "    df.tidy_tweet = df.tidy_tweet.str.replace(\"[^a-zA-Z#]\", \" \")\n",
    "    df.tidy_tweet = df.tidy_tweet.apply(lambda x: ' '.join([w for w in x.split() if len(w) > 3]))\n",
    "    tokenized_tweet = df.tidy_tweet.apply(lambda x: x.split())\n",
    "    stemmer = PorterStemmer() \n",
    "    tokenized_tweet = tokenized_tweet.apply(lambda x: [stemmer.stem(i) for i in x]) # stemming\n",
    "    for i in range(len(tokenized_tweet)):\n",
    "        tokenized_tweet[i] = ' '.join(tokenized_tweet[i])    \n",
    "        df['tidy_tweet'] = tokenized_tweet\n",
    "        df.head(10)\n",
    "    return df\n",
    "\n",
    "# function to collect hashtags \n",
    "def hashtag_extract(x):\n",
    "    hashtags = []    # Loop over the words in the tweet\n",
    "    for i in x:\n",
    "        ht = re.findall(r\"#(\\w+)\", i)\n",
    "        hashtags.append(ht)\n",
    "    return hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prepare(df_dados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dados[11]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Engenharia de features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer \n",
    "import gensim\n",
    "\n",
    "bow_vectorizer = CountVectorizer(max_df=0.90, min_df=2, max_features=200)\n",
    "bow_train = bow_vectorizer.fit_transform(df_dados['tidy_tweet'])\n",
    "bow_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.90, min_df=2, max_features=200)\n",
    "tfidf_train = tfidf_vectorizer.fit_transform(df_dados['tidy_tweet'])\n",
    "tfidf_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "tokenized_tweet = df_dados['tidy_tweet'].apply(lambda x: x.split()) # tokenizing \n",
    "\n",
    "model_w2v = gensim.models.Word2Vec(\n",
    "            tokenized_tweet,\n",
    "            size=200, # desired no. of features/independent variables\n",
    "            window=5, # context window size\n",
    "            min_count=2, # Ignores all words with total frequency lower than 2.                                  \n",
    "            sg = 1, # 1 for skip-gram model\n",
    "            hs = 0,\n",
    "            negative = 10, # for negative sampling\n",
    "            workers= 32, # no.of cores\n",
    "            seed = 34\n",
    ") \n",
    "\n",
    "model_w2v.train(tokenized_tweet, total_examples= len(df_dados['tidy_tweet']), epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_vector(tokens, size):\n",
    "    vec = np.zeros(size).reshape((1, size))\n",
    "    count = 0\n",
    "    for word in tokens:\n",
    "        try:\n",
    "            vec += model_w2v[word].reshape((1, size))\n",
    "            count += 1.\n",
    "        except KeyError:  # handling the case where the token is not in vocabulary\n",
    "            continue\n",
    "    if count != 0:\n",
    "        vec /= count\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordvec_arrays = np.zeros((len(tokenized_tweet), 200)) \n",
    "for i in range(len(tokenized_tweet)):\n",
    "    wordvec_arrays[i,:] = word_vector(tokenized_tweet[i], 200)\n",
    "wordvec_df = pd.DataFrame(wordvec_arrays)\n",
    "wordvec_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm \n",
    "# tqdm.pandas(desc=\"progress-bar\") \n",
    "from gensim.models.doc2vec import LabeledSentence\n",
    "\n",
    "def add_label(twt):\n",
    "    output = []\n",
    "    for i, s in zip(twt.index, twt):\n",
    "        output.append(LabeledSentence(s, [\"tweet_\" + str(i)]))\n",
    "    return output\n",
    "\n",
    "labeled_tweets = add_label(tokenized_tweet) # label all the tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treinar modelo doc2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "model_d2v = gensim.models.Doc2Vec(dm=1, # dm = 1 for ‘distributed memory’ model\n",
    "                                  dm_mean=1, # dm_mean = 1 for using mean of the context word vectors\n",
    "                                  vector_size=200, # no. of desired features\n",
    "                                  window=5, # width of the context window                                  \n",
    "                                  negative=7, # if > 0 then negative sampling will be used\n",
    "                                  min_count=5, # Ignores all words with total frequency lower than 5.                                  \n",
    "                                  workers=32, # no. of cores                                  \n",
    "                                  alpha=0.1, # learning rate                                  \n",
    "                                  seed = 23, # for reproducibility\n",
    "                                 ) \n",
    "\n",
    "model_d2v.build_vocab([i for i in tqdm(labeled_tweets)])\n",
    "\n",
    "model_d2v.train(labeled_tweets, total_examples= len(df_dados['tidy_tweet']), epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#cria array de vetores de documento com tamanho de acordo com quantidade de features vector_size definido no passo anterior\n",
    "docvec_arrays = np.zeros((len(tokenized_tweet), 200)) \n",
    "\n",
    "# controla qual deve ser a dimensionalidade para casar com a dimensionalidade do corpus\n",
    "for i in range(len(df_dados)):\n",
    "    docvec_arrays[i,:] = model_d2v.docvecs[i].reshape((1, 200))    \n",
    "\n",
    "docvec_df = pd.DataFrame(docvec_arrays) \n",
    "docvec_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Divisão dos dados conhecidos como  conjuntos de treinamento e de testes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pode ser feita uma divisão manual ou utilizar uma função **train_test_split** do skl que tem a vantagem de estratificar de acordo com a representatividade de cada classe no corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Definir qual percentual do conjunto de treinamento e testes irá gerar o conjunto de Treinamento\n",
    "# print(len(df_dados)*0.9)\n",
    "# print(len(df_dados)*0.1)\n",
    "\n",
    "## Cria os conjuntos de treinamento e o de testes passando o limite que divide um e o outro\n",
    "# train = df_dados[:11916] \n",
    "# test  = df_dados[11916:] \n",
    "\n",
    "# print(train.shape)\n",
    "# print(test.shape)\n",
    "\n",
    "# print(len(df_dados['tidy_tweet']))\n",
    "# print(len(df_dados['target']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df_dados['tidy_tweet']))\n",
    "print(len(df_dados['target']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "SEED = 2000\n",
    "\n",
    "x_treino, x_teste, y_treino, y_teste = train_test_split(df_dados['tidy_tweet'], df_dados['target'], test_size=0.1, random_state=SEED)\n",
    "\n",
    "print('-'*80)\n",
    "print('Dimensionalidade do conjunto de Treino              :', x_treino.shape, y_treino.shape)\n",
    "print('Dimensionalidade do conjunto de ValidaçãoTeste X e y:', x_teste.shape, y_teste.shape)\n",
    "print(np.unique(y_treino, return_counts=True))\n",
    "print(np.unique(y_teste, return_counts=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_treino[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, val in enumerate(x_treino[4:4]):\n",
    "    print(val.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_corpus = []\n",
    "for idx, val in enumerate(x_treino):\n",
    "# for i in range(1, len(x_treino)):\n",
    "    review = re.sub('[^a-zA-Z]', ' ', val)\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "\n",
    "    ps = PorterStemmer()\n",
    "\n",
    "    # stemming\n",
    "    review = [ps.stem(word) for word in review]\n",
    "\n",
    "    # joining them back with space\n",
    "    review = ' '.join(review)\n",
    "    train_corpus.append(review)\n",
    "\n",
    "test_corpus = []\n",
    "for idx, val in enumerate(x_treino):\n",
    "# for i in range(len(x_treino), len(df_dados)):\n",
    "    review = re.sub('[^a-zA-Z]', ' ', val)\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "\n",
    "    ps = PorterStemmer()\n",
    "\n",
    "    # stemming\n",
    "    review = [ps.stem(word) for word in review]\n",
    "\n",
    "    # joining them back with space\n",
    "    review = ' '.join(review)\n",
    "    test_corpus.append(review)   \n",
    "    \n",
    "# cria o bag of words do conjunto de treinamento\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Essa função do max_features define o tamanho do vetor de features que será utilizado tem que ser igual pra X e y\n",
    "cv = CountVectorizer(max_features = 1000)\n",
    "x = cv.fit_transform(train_corpus).toarray()\n",
    "y = y_treino\n",
    "\n",
    "print('dimensionalidade do X do corpus', x.shape)\n",
    "print('dimensionalidade do y do corpus', y.shape)\n",
    "\n",
    "# cria o bag of words do conjunto de teste\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(max_features = 1000)\n",
    "x_test = cv.fit_transform(test_corpus).toarray()\n",
    "\n",
    "print('dimensionalidade do conjunto de teste', x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "\n",
    "x_treino = sc.fit_transform(x_treino)\n",
    "x_valid = sc.transform(x_valid)\n",
    "x_teste = sc.transform(x_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "model.fit(x_treino, y_treino)\n",
    "\n",
    "y_pred = model.predict(x_valid)\n",
    "\n",
    "print(\"Training Accuracy :\", model.score(x_train, y_train))\n",
    "print(\"Validation Accuracy :\", model.score(x_valid, y_valid))\n",
    "\n",
    "# calculating the f1 score for the validation set\n",
    "print(\"F1 score :\", f1_score(y_valid, y_pred))\n",
    "\n",
    "# confusion matrix\n",
    "cm = confusion_matrix(y_valid, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
    "                   intercept_scaling=1, l1_ratio=None, max_iter=10000,\n",
    "                   multi_class='auto', n_jobs=-1, penalty='l2',\n",
    "                   random_state=0, tol=0.0001, verbose=0,\n",
    "                   warm_start=False)\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "y_pred = model.predict(x_valid)\n",
    "\n",
    "print(\"Training Accuracy :\", model.score(x_train, y_train))\n",
    "print(\"Validation Accuracy :\", model.score(x_valid, y_valid))\n",
    "\n",
    "# calculating the f1 score for the validation set\n",
    "print(\"f1 score :\", f1_score(y_valid, y_pred))\n",
    "\n",
    "# confusion matrix\n",
    "cm = confusion_matrix(y_valid, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "y_pred = model.predict(x_valid)\n",
    "\n",
    "print(\"Training Accuracy :\", model.score(x_train, y_train))\n",
    "print(\"Validation Accuracy :\", model.score(x_valid, y_valid))\n",
    "\n",
    "# calculating the f1 score for the validation set\n",
    "print(\"f1 score :\", f1_score(y_valid, y_pred))\n",
    "\n",
    "# confusion matrix\n",
    "cm = confusion_matrix(y_valid, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "model = SVC()\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "y_pred = model.predict(x_valid)\n",
    "\n",
    "print(\"Training Accuracy :\", model.score(x_train, y_train))\n",
    "print(\"Validation Accuracy :\", model.score(x_valid, y_valid))\n",
    "\n",
    "# calculating the f1 score for the validation set\n",
    "print(\"f1 score :\", f1_score(y_valid, y_pred))\n",
    "\n",
    "# confusion matrix\n",
    "cm = confusion_matrix(y_valid, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "model = XGBClassifier()\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "y_pred = model.predict(x_valid)\n",
    "\n",
    "print(\"Training Accuracy :\", model.score(x_train, y_train))\n",
    "print(\"Validation Accuracy :\", model.score(x_valid, y_valid))\n",
    "\n",
    "# calculating the f1 score for the validation set\n",
    "print(\"f1 score :\", f1_score(y_valid, y_pred))\n",
    "\n",
    "# confusion matrix\n",
    "cm = confusion_matrix(y_valid, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark(clf):\n",
    "    print('_' * 80)\n",
    "    print(\"Treinando o modelo: \")\n",
    "    print(clf)\n",
    "    \n",
    "    t0 = time.time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    train_time = time.time() - t0\n",
    "    print(\"Tempo de treinamento: %0.3fs\" % train_time)\n",
    "\n",
    "    t0 = time.time()\n",
    "    pred = clf.predict(X_test)\n",
    "    test_time = time.time() - t0\n",
    "    print(\"Tempo  de   testagem:  %0.3fs\" % test_time)\n",
    "\n",
    "    score = metrics.accuracy_score(y_test, pred)\n",
    "    print(\"Acurácia:   %0.3f\" % score)\n",
    "\n",
    "    print(\"Relatório Classificação e Matriz de confusão:\")\n",
    "    print(metrics.classification_report(y_test, pred,target_names=target_names))\n",
    "    print(metrics.confusion_matrix(y_test, pred))\n",
    "\n",
    "    print()\n",
    "    clf_descr = str(clf).split('(')[0]\n",
    "    return clf_descr, score, train_time, test_time\n",
    "\n",
    "results = []\n",
    "for clf, name in (\n",
    "        (RidgeClassifier(tol=1e-2, solver=\"auto\"),  \"Ridge Classifier\"),\n",
    "        (Perceptron(max_iter=1000),                 \"Perceptron\"),\n",
    "        (PassiveAggressiveClassifier(max_iter=1000),\"Passive-Aggressive\"),\n",
    "        (KNeighborsClassifier(n_neighbors=40),      \"kNN\"),\n",
    "        (RandomForestClassifier(),                  \"Random forest\")):\n",
    "    print('=' * 80)\n",
    "    print(name)\n",
    "    results.append(benchmark(clf))\n",
    "\n",
    "for penalty in [\"l2\", \"l1\"]:\n",
    "    print('=' * 80)\n",
    "    print(\"%s penalty\" % penalty.upper())\n",
    "\n",
    "    # Train Liblinear model\n",
    "    results.append(benchmark(LinearSVC(penalty=penalty, dual=False,tol=1e-3)))\n",
    "\n",
    "    # Train SGD model\n",
    "    results.append(benchmark(SGDClassifier(alpha=.0001, max_iter=1000, penalty=penalty)))\n",
    "\n",
    "# Train SGD with Elastic Net penalty\n",
    "print('=' * 80)\n",
    "print(\"Elastic-Net penalty\")\n",
    "results.append(benchmark(SGDClassifier(alpha=.0001, max_iter=1000,penalty=\"elasticnet\")))\n",
    "\n",
    "# Train NearestCentroid without threshold\n",
    "print('=' * 80)\n",
    "print(\"NearestCentroid (aka Rocchio classifier)\")\n",
    "results.append(benchmark(NearestCentroid()))\n",
    "\n",
    "# Train sparse Naive Bayes classifiers\n",
    "print('=' * 80)\n",
    "print(\"Naive Bayes\")\n",
    "results.append(benchmark(MultinomialNB(alpha=.01)))\n",
    "results.append(benchmark(BernoulliNB(alpha=.01)))\n",
    "results.append(benchmark(ComplementNB(alpha=.1)))\n",
    "\n",
    "print('=' * 80)\n",
    "print(\"LinearSVC with L1-based feature selection\")\n",
    "\n",
    "# Com SVMs e regressão logística, o parâmetro C controla a esparsidade: quanto menor C, menos recursos selecionados.\n",
    "results.append(benchmark(Pipeline([\n",
    "  ('feature_selection', SelectFromModel(LinearSVC(penalty=\"l1\", dual=False, tol=1e-3))),\n",
    "  ('classification', LinearSVC(penalty=\"l2\"))])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_a  = pd.read_csv('datasets/testset-levela.tsv', sep='\\t', usecols=('id','tweet'))\n",
    "task_a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "task_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_b  = pd.read_csv('datasets/testset-levelb.tsv', sep='\\t', usecols=('id','tweet'))\n",
    "task_b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "stopwords.append('NaN')\n",
    "stopwords.append('URL')\n",
    "stopwords.append('url')\n",
    "stopwords.append('USER')\n",
    "stopwords.append('user')\n",
    "\n",
    "# print('Stopwords NLTK: ', stopwords)\n",
    "\n",
    "lst_remstopwords = []\n",
    "\n",
    "for sentence in linhas:\n",
    "    sentence_lower = sentence.lower()\n",
    "#     print(sentence_lower)\n",
    "    linha = sentence_lower.split()\n",
    "    new_sentence =' '.join([word for word in linha if word not in stopwords])\n",
    "#     print(new_sentence)\n",
    "    lst_remstopwords.append(new_sentence)\n",
    "\n",
    "x = pd.Series(lst_remstopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dados[\"subtask_a\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dados = pd.concat([x], axis=1)\n",
    "df_dados.columns = ['tweets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dados = pd.concat([traintest['tweet'], traintest['subtask_a'], x, y], axis=1)\n",
    "df_dados.columns = ['tweet','subtask_a','tweet_limpo','target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_dados[\"subtask_a\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Normalização de texto**\n",
    "\n",
    "Aqui, usaremos a função PorterStemmer () da nltk para normalizar os tweets. Mas antes disso teremos que tokenizar os tweets. Tokens são termos ou palavras individuais, e a tokenização é o processo de dividir uma sequência de texto em tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_tweet = df_dados.tweet_limpo.apply(lambda x: x.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import * \n",
    "stemmer = PorterStemmer() \n",
    "tokenized_tweet = tokenized_tweet.apply(lambda x: [stemmer.stem(i) for i in x]) # stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dados = pd.concat([df_dados['subtask_a'], df_dados['target'], df_dados['tweet_limpo'], tokenized_tweet], axis=1)\n",
    "df_dados.columns = ['subtask_a','target','tweet_limpo','tokenized_tweet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Features por Frequência absoluta (Bag-of-Words)\n",
    "\n",
    "Para analisar dados pré-processados, eles precisam ser convertidos em features. Dependendo do uso, os features de texto podem ser construídos usando técnicas variadas - Bag of Words, TF-IDF e Word Embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer \n",
    "import gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos começar com os recursos ** Bag-of-Words **.\n",
    "\n",
    "Considere um Corpus C de D documentos {d1, d2… ..dD} e N tokens exclusivos extraídos do corpus C. Os N tokens (palavras) formarão um dicionário e o tamanho da matriz de palavras-chave M DX N. Cada linha na matriz M contém a frequência de tokens no documento D (i).\n",
    "\n",
    "Vamos entender isso usando um exemplo simples.\n",
    "\n",
    "D1: Ele é um garoto preguiçoso. Ela também é preguiçosa.\n",
    "\n",
    "D2: Smith é uma pessoa preguiçosa.\n",
    "\n",
    "O dicionário criado seria uma lista de tokens exclusivos no corpus = ['Ele', 'Ela', 'preguiçoso', 'garoto', 'Smith', 'pessoa']\n",
    "\n",
    "Aqui, D = 2, N = 6\n",
    "\n",
    "A matriz M de tamanho 2 X 6 será representada como -![imgur](https://i.imgur.com/mKcTPdZ.png)\n",
    "\n",
    "Agora, as colunas na matriz acima podem ser usadas como recursos para criar um modelo de classificação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traintest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_vectorizer = CountVectorizer(max_df=0.90, min_df=2, max_features=1000, stop_words='english')\n",
    "bow = bow_vectorizer.fit_transform(traintest['tweet'])\n",
    "bow.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Features por frequência relativa (TF-IDF)\n",
    "\n",
    "Esse é outro método que se baseia no método de frequência, mas é diferente da abordagem do saco de palavras, no sentido de levar em conta não apenas a ocorrência de uma palavra em um único documento (ou tweet), mas em todo o corpus.\n",
    "\n",
    "O TF-IDF funciona penalizando as palavras comuns, atribuindo-lhes pesos mais baixos e dando importância a palavras raras em todo o corpus, mas que aparecem em bons números em poucos documentos.\n",
    "\n",
    "Vamos dar uma olhada nos termos importantes relacionados ao TF-IDF:\n",
    "\n",
    "* TF = (número de vezes que o termo t aparece em um documento) / (número de termos no documento)\n",
    "\n",
    "* IDF = log (N / n), em que N é o número de documentos en é o número de documentos em que um termo t apareceu.\n",
    "\n",
    "* TF-IDF = TF * IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.90, min_df=2, max_features=1000, stop_words='english')\n",
    "tfidf = tfidf_vectorizer.fit_transform(df_dados['tweet_limpo'])\n",
    "tfidf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Word2Vec Features\n",
    "\n",
    "Incorporação de palavras é a maneira moderna de representar palavras como vetores. O objetivo de incorporar palavras é redefinir os recursos de palavras de alta dimensão em vetores de características de baixa dimensão, preservando a similaridade contextual no corpus. Eles são capazes de realizar tarefas como ** Rei-homem + mulher = Rainha **, o que é alucinante.\n",
    "![imgur](https://i.imgur.com/gZiNamE.png)\n",
    "\n",
    "As vantagens de usar combinações de palavras sobre BOW ou TF-IDF são:\n",
    "\n",
    "1. Redução de dimensionalidade - redução significativa no não. dos recursos necessários para construir um modelo.\n",
    "\n",
    "1. Ele captura significados das palavras, relacionamentos semânticos e os diferentes tipos de contextos em que são usados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Word2Vec Embeddings**\n",
    "\n",
    "O Word2Vec não é um algoritmo único, mas uma combinação de duas técnicas - modelo ** CBOW (Contínuo de palavras contínuas) ** e ** Skip-gram **. Ambas são redes neurais rasas que mapeiam palavras para a variável alvo, que também é uma palavra. Ambas as técnicas aprendem pesos que atuam como representações de vetores de palavras.\n",
    "\n",
    "O CBOW tende a prever a probabilidade de uma palavra em um contexto. Um contexto pode ser uma única palavra adjacente ou um grupo de palavras ao redor. O modelo Skip-gram funciona de maneira inversa, tenta prever o contexto de uma determinada palavra.\n",
    "\n",
    "Abaixo está uma representação esquemática de um modelo Word2Vec da janela de contexto de 1 palavra.\n",
    "\n",
    "![imgur](https://i.imgur.com/f77V0dH.png)\n",
    "\n",
    "Existem três laters: - uma camada de entrada, - uma camada oculta e - uma camada de saída.\n",
    "\n",
    "A camada de entrada e a saída são codificadas em um tamanho quente [1 X V], onde V é o tamanho do vocabulário (número de palavras únicas no corpus). A camada de saída é uma camada softmax que é usada para somar as probabilidades obtidas na camada de saída para 1. Os pesos aprendidos pelo modelo são então usados como vetores de palavras.\n",
    "\n",
    "Iremos adiante com o modelo Skip-gram, pois possui as seguintes vantagens:\n",
    "\n",
    "* Ele pode capturar duas semânticas para uma única palavra. ou seja, ele terá duas representações vetoriais de 'maçã'. Um para a empresa Apple e outro para a fruta.\n",
    "\n",
    "* O pula-grama com subamostragem negativa supera o CBOW em geral.\n",
    "\n",
    "Treinaremos um modelo Word2Vec em nossos dados para obter representações vetoriais para todas as palavras únicas presentes em nosso corpus. Há mais uma opção de usar **vetores de palavras pré-treinados** em vez de treinar nosso próprio modelo. Alguns dos vetores pré-treinados disponíveis gratuitamente são:\n",
    "\n",
    "1. [Google News Word Vectors](https://code.google.com/archive/p/word2vec/)\n",
    "\n",
    "1. [Freebase names](https://code.google.com/archive/p/word2vec/)\n",
    "\n",
    "1. [DBPedia vectors (wiki2vec)](https://github.com/idio/wiki2vec#prebuilt-models)\n",
    "\n",
    "No entanto, por enquanto, treinaremos nossos próprios vetores de palavras, já que o tamanho dos vetores de palavras pré-treinados geralmente é enorme.\n",
    "\n",
    "Vamos treinar um modelo Word2Vec em nosso corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "tokenized_tweet = df_dados['tweet_limpo'].apply(lambda x: x.split()) # tokenizing \n",
    "\n",
    "model_w2v = gensim.models.Word2Vec(\n",
    "            tokenized_tweet,\n",
    "            size=200, # desired no. of features/independent variables\n",
    "            window=5, # context window size\n",
    "            min_count=2, # Ignores all words with total frequency lower than 2.                                  \n",
    "            sg = 1, # 1 for skip-gram model\n",
    "            hs = 0,\n",
    "            negative = 10, # for negative sampling\n",
    "            workers= 32, # no.of cores\n",
    "            seed = 34\n",
    ") \n",
    "\n",
    "model_w2v.train(tokenized_tweet, total_examples= len(x_train['tweet']), epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos brincar um pouco com o nosso modelo Word2Vec e ver como ele funciona. Especificaremos uma palavra e o modelo retirará as palavras mais relacionadas com ela do corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_w2v.wv.most_similar(positive=\"night\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_w2v['food']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(model_w2v['food']) #The length of the vector is 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparando vetores para tweets\n",
    "\n",
    "Como nossos dados contêm tweets e não apenas palavras, teremos que descobrir uma maneira de usar os vetores de palavras do modelo word2vec para criar uma representação vetorial para um tweet inteiro. Existe uma solução simples para esse problema, podemos simplesmente tirar a média de todos os vetores de palavras presentes no tweet. O comprimento do vetor resultante será o mesmo, ou seja, 200. Repetiremos o mesmo processo para todos os tweets em nossos dados e obteremos seus vetores. Agora, temos 200 recursos word2vec para nossos dados.\n",
    "\n",
    "Usaremos a função abaixo para criar um vetor para cada tweet, calculando a média dos vetores das palavras presentes no tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_vector(tokens, size):\n",
    "    vec = np.zeros(size).reshape((1, size))\n",
    "    count = 0\n",
    "    for word in tokens:\n",
    "        try:\n",
    "            vec += model_w2v[word].reshape((1, size))\n",
    "            count += 1.\n",
    "        except KeyError:  # handling the case where the token is not in vocabulary\n",
    "            continue\n",
    "    if count != 0:\n",
    "        vec /= count\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparando o conjunto de recursos do word2vec…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordvec_arrays = np.zeros((len(tokenized_tweet), 200)) \n",
    "for i in range(len(tokenized_tweet)):\n",
    "    wordvec_arrays[i,:] = word_vector(tokenized_tweet[i], 200)\n",
    "wordvec_df = pd.DataFrame(wordvec_arrays)\n",
    "wordvec_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, temos 200 novos features, enquanto no Bag of Words e no TF-IDF tínhamos 1000 features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Embedding por Doc2Vec\n",
    "\n",
    "O modelo Doc2Vec é um algoritmo não supervisionado para gerar vetores para sentenças / parágrafos / documentos. Essa abordagem é uma extensão da word2vec. A principal diferença entre os dois é que o doc2vec fornece um contexto adicional exclusivo para todos os documentos do corpus. Esse contexto adicional não passa de outro vetor de recurso para todo o documento. Este vetor de documento é treinado junto com os vetores de palavras.\n",
    "\n",
    "![imgur](https://i.imgur.com/RBlg4xJ.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm \n",
    "# tqdm.pandas(desc=\"progress-bar\") \n",
    "from gensim.models.doc2vec import LabeledSentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para implementar o doc2vec, temos que **labelise** or **tag** cada tweet tokenizado com IDs exclusivos. Podemos fazer isso usando a função *LabeledSentence()* da Gensim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_label(twt):\n",
    "    output = []\n",
    "    for i, s in zip(twt.index, twt):\n",
    "        output.append(LabeledSentence(s, [\"tweet_\" + str(i)]))\n",
    "    return output\n",
    "\n",
    "labeled_tweets = add_label(tokenized_tweet) # label all the tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_tweets[:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos treinar um modelo **doc2vec**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "model_d2v = gensim.models.Doc2Vec(dm=1,              # dm = 1 for ‘distributed memory’ model\n",
    "                                  dm_mean=1,         # dm_mean = 1 for using mean of the context word vectors\n",
    "                                  vector_size=200,   # no. of desired features\n",
    "                                  window=5,          # width of the context window                                  \n",
    "                                  negative=7,        # if > 0 then negative sampling will be used\n",
    "                                  min_count=5,       # Ignores all words with total frequency lower than 5.                                  \n",
    "                                  workers=32,        # no. of cores                                  \n",
    "                                  alpha=0.1,         # learning rate                                  \n",
    "                                  seed = 500,        # for reproducibility\n",
    "                                 ) \n",
    "\n",
    "model_d2v.build_vocab([i for i in tqdm(labeled_tweets)])\n",
    "\n",
    "model_d2v.train(labeled_tweets, total_examples= len(x_train['tweet']), epochs=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preparando o Conjunto de Features doc2vec**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docvec_arrays = np.zeros((len(tokenized_tweet), 200)) \n",
    "for i in range(len(x_train)):\n",
    "    docvec_arrays[i,:] = model_d2v.docvecs[i].reshape((1,200))    \n",
    "\n",
    "docvec_df = pd.DataFrame(docvec_arrays) \n",
    "docvec_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora concluímos todas as etapas de pré-modelagem necessárias para obter os dados no formato adequados. Criaremos modelos nos conjuntos de dados com diferentes conjuntos de recursos preparados nas seções anteriores - Bag-of-Words, TF-IDF, vetores word2vec e vetores doc2vec. Usaremos os seguintes algoritmos para criar modelos:\n",
    "\n",
    "1. Regressão logística\n",
    "2. Máquina de vetores de suporte\n",
    "3. RandomForest\n",
    "4. XGBoost\n",
    "\n",
    "**Métrica de avaliação**\n",
    "\n",
    "**Escore F1** está sendo usado como métrica de avaliação. É a média ponderada de Precisão e Recuperação. Portanto, essa pontuação leva em consideração tanto os falsos positivos quanto os falsos negativos. É adequado para problemas de distribuição de classe desigual.\n",
    "\n",
    "Os componentes importantes da pontuação F1 são:\n",
    "\n",
    "1. True Positives (TP) - Estes são os valores positivos previstos corretamente, o que significa que o valor da classe real é sim e o valor da classe prevista também é sim.\n",
    "1. True Negatives (TN) - Esses são os valores negativos previstos corretamente, o que significa que o valor da classe real é não e o valor da classe prevista também é não.\n",
    "1. False Positives (FP) – Quando a classe real é não e a classe prevista é sim.\n",
    "1. False Negatives (FN) – Quando a classe real é sim, mas a classe prevista em não.\n",
    "\n",
    "**Precisão** = TP/(TP+FP)\n",
    "\n",
    "**Cobertura** = TP/(TP+FN)\n",
    "\n",
    "**F1 Score** = 2(Cobertura * Precisão) / (Cobertura + Precisão)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regressão Logística\n",
    "\n",
    "Regressão logística é um algoritmo de classificação. É usado para prever um resultado binário (1 / 0, Sim / Não, Verdadeiro / Falso), dado um conjunto de variáveis independentes. Você também pode pensar em regressão logística como um caso especial de regressão linear quando a variável de resultado é categórica, onde estamos usando o log de chances como a variável dependente. Em palavras simples, ele prevê a probabilidade de ocorrência de um evento ajustando dados a uma função de logit.\n",
    "\n",
    "A seguinte equação é usada em Regressão logística:\n",
    "\n",
    "![imgur](https://i.imgur.com/RpFof26.png)\n",
    "\n",
    "Um gráfico típico do modelo logístico é mostrado abaixo. Você pode ver que a probabilidade nunca fica abaixo de 0 e acima de 1.\n",
    "\n",
    "![imgur](https://i.imgur.com/vX2dlga.png)\n",
    "\n",
    "Ler esse [artigo](https://www.analyticsvidhya.com/blog/2015/11/beginners-guide-on-logistic-regression-in-r/) para saber mais sobre a regressão logística.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Features de Bag-of-Words**\n",
    "\n",
    "Primeiro tentaremos ajustar o modelo de regressão logística nos featrues de Bag of Words (BoW)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.Series(train['tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape, x_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bow = bow[:9930,:]\n",
    "train_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=13240*0.75\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_bow = bow[9930:,:]\n",
    "test_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Começar aqui ----------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carga de dados para treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_dados = pd.read_csv('datasets/olid-training-v1.0.tsv', sep='\\t', usecols=('id','tweet','subtask_a','subtask_b','subtask_c'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limpeza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import * \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "def remove_pattern(input_txt, pattern):\n",
    "    r = re.findall(pattern, input_txt)\n",
    "    for i in r:\n",
    "        input_txt = re.sub(i, '', input_txt)\n",
    "    return input_txt\n",
    "\n",
    "def prepare(df):\n",
    "    df['tidy_tweet'] = np.vectorize(remove_pattern)(df['tweet'], \"@[\\w]*\") \n",
    "    df.tidy_tweet = df.tidy_tweet.str.replace(\"[^a-zA-Z#]\", \" \")\n",
    "    df.tidy_tweet = df.tidy_tweet.apply(lambda x: ' '.join([w for w in x.split() if len(w) > 3]))\n",
    "    tokenized_tweet = df.tidy_tweet.apply(lambda x: x.split())\n",
    "    stemmer = PorterStemmer() \n",
    "    tokenized_tweet = tokenized_tweet.apply(lambda x: [stemmer.stem(i) for i in x]) # stemming\n",
    "    for i in range(len(tokenized_tweet)):\n",
    "        tokenized_tweet[i] = ' '.join(tokenized_tweet[i])    \n",
    "        df['tidy_tweet'] = tokenized_tweet\n",
    "        df.head(10)\n",
    "    return df\n",
    "\n",
    "# function to collect hashtags \n",
    "def hashtag_extract(x):\n",
    "    hashtags = []    # Loop over the words in the tweet\n",
    "    for i in x:\n",
    "        ht = re.findall(r\"#(\\w+)\", i)\n",
    "        hashtags.append(ht)\n",
    "    return hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare(df_dados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# binarização dos targets\n",
    "import numpy as np\n",
    "off = 2\n",
    "dy = []\n",
    "for k in df_dados['subtask_a']:\n",
    "#     print('Estado inicial:',k)\n",
    "    if k == 'OFF':\n",
    "        off = 1\n",
    "#         print('Setado para:   ',off,'\\n')\n",
    "        dy.append(off)\n",
    "    elif k == 'NOT':\n",
    "        off = 0\n",
    "#         print('Setado para:   ',off,'\\n')\n",
    "        dy.append(off)\n",
    "    else:\n",
    "        off= 2\n",
    "\n",
    "y = pd.Series(dy)\n",
    "\n",
    "df_dados = pd.concat([df_dados['tidy_tweet'], df_dados['subtask_a'], y], axis=1)\n",
    "df_dados.columns = ['tidy_tweet','subtask_a', 'target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features para treinamento por TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df_dados['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer \n",
    "import gensim\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.90, min_df=2, max_features=1000, stop_words='english')\n",
    "tfidf = tfidf_vectorizer.fit_transform(df_dados['tidy_tweet'])\n",
    "tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features do Held-Out-Data level_a - (supervisão de Cecília)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heldout_a = pd.read_csv('datasets/testset-levela.tsv', sep='\\t', usecols=('id','tweet'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prepare(heldout_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# heldout_a.index = heldout_a.id\n",
    "hoda_index = pd.Series(heldout_a['id'])\n",
    "hoda_tweet = pd.Series(heldout_a['tweet'])\n",
    "heldout_a.drop(['tweet'], axis=1, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer \n",
    "import gensim\n",
    "\n",
    "tfidf_vechod = TfidfVectorizer(max_df=0.90, min_df=2, max_features=1000, stop_words='english')\n",
    "tfidf_hoda = tfidf_vechod.fit_transform(heldout_a['tidy_tweet'])\n",
    "print(tfidf_hoda.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "model = XGBClassifier()\n",
    "model.fit(tfidf, y)\n",
    "\n",
    "y_pred = model.predict(tfidf_hoda)\n",
    "hoda_ypred = pd.Series(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_a = pd.concat([hoda_index, hoda_tweet, hoda_ypred], axis=1)\n",
    "result_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parei aqui ------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our tuning worked! This is our best score!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = xgb_model.predict(dtest)\n",
    "test['label'] = (test_pred >= 0.3).astype(np.int)\n",
    "submission = test[['id','label']] \n",
    "submission.to_csv('sub_xgb_w2v_finetuned.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = xgb.train(\n",
    "    params,\n",
    "    dtrain,\n",
    "    feval= custom_eval,\n",
    "    num_boost_round= 1000,\n",
    "    maximize=True,\n",
    "    evals=[(dvalid, \"Validation\")],\n",
    "    early_stopping_rounds=10\n",
    " )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, agora podemos usar esses parâmetros ajustados em nosso modelo xgboost. Usamos a parada antecipada de 10, o que significa que, se o desempenho do modelo não melhorar em menos de 10 rodadas, o treinamento do modelo será interrompido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'colsample': 0.9,\n",
    "    'colsample_bytree': 0.5,\n",
    "    'eta': 0.1,\n",
    "    'max_depth': 9,\n",
    "    'min_child_weight': 7,\n",
    "    'objective': 'binary:logistic',\n",
    "    'subsample': 0.9\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s have a look at the final list of tuned parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_f1 = 0. \n",
    "best_params = None \n",
    "for eta in [.3, .2, .1, .05, .01, .005]:\n",
    "    print(\"CV with eta={}\".format(eta))\n",
    "     # Update ETA\n",
    "    params['eta'] = eta\n",
    "\n",
    "     # Run CV\n",
    "    cv_results = xgb.cv(\n",
    "        params,\n",
    "        dtrain,\n",
    "        feval= custom_eval,\n",
    "        num_boost_round=1000,\n",
    "        maximize=True,\n",
    "        seed=16,\n",
    "        nfold=5,\n",
    "        early_stopping_rounds=20\n",
    "    )\n",
    "\n",
    "    # Finding best F1 Score\n",
    "    mean_f1 = cv_results['test-f1_score-mean'].max()\n",
    "    boost_rounds = cv_results['test-f1_score-mean'].idxmax()\n",
    "    print(\"\\tF1 Score {} for {} rounds\".format(mean_f1, boost_rounds))\n",
    "    \n",
    "    if mean_f1 > max_f1:\n",
    "        max_f1 = mean_f1\n",
    "        best_params = eta \n",
    "        \n",
    "print(\"Best params: {}, F1 Score: {}\".format(best_params, max_f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let’s tune the *learning rate*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['subsample'] = 0.9\n",
    "params['colsample_bytree'] = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Updating *subsample* and *colsample_bytree*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridsearch_params = [\n",
    "    (subsample, colsample)\n",
    "    for subsample in [i/10. for i in range(5,10)]\n",
    "    for colsample in [i/10. for i in range(5,10)]\n",
    "]\n",
    "\n",
    "max_f1 = 0. \n",
    "best_params = None \n",
    "\n",
    "for subsample, colsample in gridsearch_params:\n",
    "    print(\"CV with subsample={}, colsample={}\".format(subsample,colsample))\n",
    "    \n",
    "    # Update our parameters\n",
    "    params['colsample'] = colsample\n",
    "    params['subsample'] = subsample\n",
    "    \n",
    "    cv_results = xgb.cv(\n",
    "        params,\n",
    "        dtrain,\n",
    "        feval= custom_eval,\n",
    "        num_boost_round=200,\n",
    "        maximize=True,\n",
    "        seed=16,\n",
    "        nfold=5,\n",
    "        early_stopping_rounds=10\n",
    "        )\n",
    "    \n",
    "    # Finding best F1 Score\n",
    "    mean_f1 = cv_results['test-f1_score-mean'].max()\n",
    "    boost_rounds = cv_results['test-f1_score-mean'].idxmax()\n",
    "    print(\"\\tF1 Score {} for {} rounds\".format(mean_f1, boost_rounds))\n",
    "    \n",
    "    if mean_f1 > max_f1:\n",
    "        max_f1 = mean_f1\n",
    "        best_params = (subsample, colsample) \n",
    "\n",
    "print(\"Best params: {}, {}, F1 Score: {}\".format(best_params[0], best_params[1], max_f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tuning *subsample* and *colsample*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['max_depth'] = 9 \n",
    "params['min_child_weight'] = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Updating max_depth and min_child_weight parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridsearch_params = [\n",
    "    (max_depth, min_child_weight)\n",
    "    for max_depth in range(6,10)\n",
    "    for min_child_weight in range(5,8)\n",
    "    ]\n",
    "\n",
    "max_f1 = 0. # initializing with 0 \n",
    "\n",
    "best_params = None \n",
    "\n",
    "for max_depth, min_child_weight in gridsearch_params:\n",
    "    print(\"CV with max_depth={}, min_child_weight={}\".format(max_depth,min_child_weight))\n",
    "    \n",
    "     # Update our parameters\n",
    "    params['max_depth'] = max_depth\n",
    "    params['min_child_weight'] = min_child_weight\n",
    "\n",
    "     # Cross-validation\n",
    "    cv_results = xgb.cv(\n",
    "        params,\n",
    "        dtrain,\n",
    "        feval= custom_eval,\n",
    "        num_boost_round=200,\n",
    "        maximize=True,\n",
    "        seed=16,\n",
    "        nfold=5,\n",
    "        early_stopping_rounds=10\n",
    "        )     \n",
    "    \n",
    "# Finding best F1 Score    \n",
    "mean_f1 = cv_results['test-f1_score-mean'].max()\n",
    "boost_rounds = cv_results['test-f1_score-mean'].idxmax()    \n",
    "print(\"\\tF1 Score {} for {} rounds\".format(mean_f1, boost_rounds))    \n",
    "\n",
    "if mean_f1 > max_f1:\n",
    "        max_f1 = mean_f1\n",
    "        best_params = (max_depth,min_child_weight) \n",
    "\n",
    "print(\"Best params: {}, {}, F1 Score: {}\".format(best_params[0], best_params[1], max_f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Abordagem geral para ajuste de parâmetros **\n",
    "\n",
    "Seguiremos as etapas abaixo para ajustar os parâmetros.\n",
    "\n",
    "1. Escolha uma taxa de aprendizado relativamente alta. Normalmente, uma taxa de aprendizado de 0,3 é usada nesta fase.\n",
    "\n",
    "2. Ajuste parâmetros específicos da árvore, como max_depth, min_child_weight, subsample, colsample_bytree, mantendo a taxa de aprendizado fixa.\n",
    "\n",
    "3. Ajuste a taxa de aprendizado.\n",
    "\n",
    "4. Finalmente, ajuste a gama para evitar ajustes excessivos.\n",
    "\n",
    "* Ajustando max_depth e min_child_weight *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_eval(preds, dtrain):\n",
    "    labels = dtrain.get_label().astype(np.int)\n",
    "    preds = (preds >= 0.3).astype(np.int)\n",
    "    return [('f1_score', f1_score(labels, preds))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will prepare a custom evaluation metric to calculate F1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(xtrain_w2v, label=ytrain) \n",
    "dvalid = xgb.DMatrix(xvalid_w2v, label=yvalid) \n",
    "dtest  = xgb.DMatrix(test_w2v)\n",
    "# Parameters that we are going to tune \n",
    "params = {\n",
    "    'objective':'binary:logistic',\n",
    "    'max_depth':6,\n",
    "    'min_child_weight': 1,\n",
    "    'eta':.3,\n",
    "    'subsample': 1,\n",
    "    'colsample_bytree': 1\n",
    " }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui vamos usar o DMatrices. Uma DMatrix pode conter os recursos e o destino."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FineTuning XGBoost + Word2Vec\n",
    "\n",
    "XGBoost with Word2Vec model has given us the best performance so far. Let’s try to tune it further to extract as much from it as we can. XGBoost has quite a many tuning parameters and sometimes it becomes tricky to properly tune them. This is what we are going to do in the following steps. You can refer this guide to learn more about parameter tuning in XGBoost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBClassifier(max_depth=6, n_estimators=1000, nthread= 3).fit(xtrain_d2v, ytrain) \n",
    "prediction = xgb.predict(xvalid_d2v)\n",
    "f1_score(yvalid, prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Doc2Vec Features**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost model on word2vec features has outperformed all the previuos models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBClassifier(max_depth=6, n_estimators=1000, nthread= 3).fit(xtrain_w2v, ytrain) \n",
    "prediction = xgb.predict(xvalid_w2v)\n",
    "f1_score(yvalid, prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Word2Vec Features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBClassifier(max_depth=6, n_estimators=1000).fit(xtrain_tfidf, ytrain) \n",
    "prediction = xgb.predict(xvalid_tfidf)\n",
    "f1_score(yvalid, prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TF-IDF Features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = xgb_model.predict(test_bow)\n",
    "test['label'] = test_pred\n",
    "submission = test[['id','label']]\n",
    "submission.to_csv('sub_xgb_bow.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = XGBClassifier(max_depth=6, n_estimators=1000).fit(xtrain_bow, ytrain)\n",
    "prediction = xgb_model.predict(xvalid_bow)\n",
    "f1_score(yvalid, prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bag-of-Words Features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost\n",
    "\n",
    "Extreme Gradient Boosting (xgboost) is an advanced implementation of gradient boosting algorithm. It has both linear model solver and tree learning algorithms. Its ability to do parallel computation on a single machine makes it extremely fast. It also has additional features for doing cross validation and finding important variables. There are many parameters which need to be controlled to optimize the model.\n",
    "\n",
    "Some key benefits of XGBoost are:\n",
    "\n",
    "1. **Regularization** - helps in reducing overfitting\n",
    "\n",
    "1. **Parallel Processing** - XGBoost implements parallel processing and is blazingly faster as compared to GBM.\n",
    "\n",
    "1. **Handling Missing Values** - It has an in-built routine to handle missing values.\n",
    "\n",
    "1. **Built-in Cross-Validation** - allows user to run a cross-validation at each iteration of the boosting process\n",
    "\n",
    "Check out this wonderful guide on XGBoost parameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=400, random_state=11).fit(xtrain_d2v, ytrain) \n",
    "prediction = rf.predict(xvalid_d2v)\n",
    "f1_score(yvalid, prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Doc2Vec Features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=400, random_state=11).fit(xtrain_w2v, ytrain) \n",
    "prediction = rf.predict(xvalid_w2v)\n",
    "f1_score(yvalid, prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Word2Vec Features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=400, random_state=11).fit(xtrain_tfidf, ytrain) \n",
    "prediction = rf.predict(xvalid_tfidf)\n",
    "f1_score(yvalid, prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TF-IDF Features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = rf.predict(test_bow)\n",
    "test['subtask_a'] = test_pred\n",
    "submission = test[['id','subtask_a']]\n",
    "submission.to_csv('sub_rf_bow.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s make predictions for the test dataset and create another submission file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=400, random_state=11).fit(xtrain_bow, ytrain) \n",
    "prediction = rf.predict(xvalid_bow) \n",
    "f1_score(yvalid, prediction) # validation score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bag-of-Words Features**\n",
    "\n",
    "First we will train our RandomForest model on the Bag-of-Words features and check its performance on validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForest\n",
    "\n",
    "Random Forest é um algoritmo versátil de aprendizado de máquina capaz de executar tarefas de regressão e classificação. É um tipo de método de aprendizado de conjunto, em que alguns modelos fracos se combinam para formar um modelo poderoso. Na Floresta Aleatória, crescemos várias árvores em oposição a uma única árvore de decisão. Para classificar um novo objeto com base em atributos, cada árvore dá uma classificação e dizemos que a árvore “vota” para essa classe. A floresta escolhe a classificação com mais votos (sobre todas as árvores da floresta).\n",
    "Funciona da seguinte maneira. Cada árvore é plantada e cultivada da seguinte forma:\n",
    "\n",
    "1. Suponha que o número de casos no conjunto de treinamento seja N. Em seguida, uma amostra desses N casos é coletada aleatoriamente, mas com substituição. Esta amostra será o conjunto de treinamento para o cultivo da árvore.\n",
    "\n",
    "2. Se houver M variáveis de entrada, um número m (m <M) é especificado de modo que, em cada nó, m variáveis sejam selecionadas aleatoriamente dentre M. A melhor divisão nessas m variáveis é usada para dividir o nó. O valor de m é mantido constante enquanto cultivamos a floresta.\n",
    "\n",
    "3. Cada árvore é cultivada na maior extensão possível e não há poda.\n",
    "\n",
    "4. Preveja novos dados agregando as previsões das árvores ntree (ou seja, maioria dos votos na classificação e média na regressão).\n",
    "![imgur](https://i.imgur.com/nOBROEn.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = svm.SVC(kernel='linear', C=1, probability=True).fit(xtrain_d2v, ytrain) \n",
    "\n",
    "prediction     = svc.predict_proba(xvalid_d2v) \n",
    "prediction_int = prediction[:,1] >= 0.3 \n",
    "prediction_int = prediction_int.astype(np.int) \n",
    "\n",
    "f1_score(yvalid, prediction_int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Doc2Vec Features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = svm.SVC(kernel='linear', C=1, probability=True).fit(xtrain_w2v, ytrain) \n",
    "\n",
    "prediction     = svc.predict_proba(xvalid_w2v) \n",
    "prediction_int = prediction[:,1] >= 0.3 \n",
    "prediction_int = prediction_int.astype(np.int) \n",
    "\n",
    "f1_score(yvalid, prediction_int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Word2Vec Features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = svm.SVC(kernel='linear', C=1, probability=True).fit(xtrain_tfidf, ytrain) \n",
    "\n",
    "prediction     = svc.predict_proba(xvalid_tfidf) \n",
    "prediction_int = prediction[:,1] >= 0.3 \n",
    "prediction_int = prediction_int.astype(np.int) \n",
    "\n",
    "f1_score(yvalid, prediction_int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TF-IDF Features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neste caso, a pontuação da validação foi um pouco menor que a pontuação da Regressão logística para recursos de palavras-chave."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "xtrain_bow =\n",
    "ytrain     =\n",
    "xvalid_bow =\n",
    "yvalid     =\n",
    "\n",
    "svc = svm.SVC(kernel='linear', C=1, probability=True).fit(xtrain_bow, ytrain) \n",
    "\n",
    "prediction     = svc.predict_proba(xvalid_bow) \n",
    "prediction_int = prediction[:,1] >= 0.3 \n",
    "prediction_int = prediction_int.astype(np.int) \n",
    "\n",
    "f1_score(yvalid, prediction_int)\n",
    "\n",
    "## Novamente, vamos fazer previsões para o conjunto de dados de teste e criar outro arquivo de envio.\n",
    "test_pred     = svc.predict_proba(test_bow) \n",
    "test_pred_int = test_pred[:,1] >= 0.3 \n",
    "test_pred_int = test_pred_int.astype(np.int) \n",
    "test['label'] = test_pred_int \n",
    "\n",
    "submission = test[['id','label']] \n",
    "submission.to_csv('sub_svm_bow.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xvalid_bow = bow_a\n",
    "bow_a.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bag-of-Words Features**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine (SVM)\n",
    "\n",
    "O Support Vector Machine (SVM) é um algoritmo de aprendizado de máquina supervisionado que pode ser usado para desafios de classificação ou regressão. No entanto, é usado principalmente em problemas de classificação. Nesse algoritmo, plotamos cada item de dados como um ponto no espaço n-dimensional (onde n é o número de recursos que você possui), com o valor de cada recurso sendo o valor de uma determinada coordenada. Em seguida, realizamos a classificação encontrando o hiperplano que diferencia as duas classes, conforme mostrado no gráfico abaixo:\n",
    "\n",
    "![imgur](https://i.imgur.com/dG1jOCx.png)\n",
    "\n",
    "Consulte este [artigo](https://www.analyticsvidhya.com/blog/2017/09/understaing-support-vector-machine-example-code/) para saber mais sobre o SVM. Agora, implementaremos o SVM em nossos dados usando a biblioteca scikit-learn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doc2Vec features do not seem to be capturing the right signals as the F1-score on validation set is quite low."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_d2v = docvec_df.iloc[:9000,:]\n",
    "test_d2v = docvec_df.iloc[9000:,:] \n",
    "\n",
    "xtrain_d2v = train_d2v.iloc[ytrain.index,:]\n",
    "xvalid_d2v = train_d2v.iloc[yvalid.index,:]\n",
    "\n",
    "lreg.fit(xtrain_d2v, ytrain) \n",
    "\n",
    "prediction = lreg.predict_proba(xvalid_d2v)\n",
    "\n",
    "prediction_int = prediction[:,1] >= 0.3\n",
    "prediction_int = prediction_int.astype(np.int)\n",
    "\n",
    "f1_score(yvalid, prediction_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docvec_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Doc2Vec Features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_w2v = wordvec_df.iloc[:31962,:]\n",
    "test_w2v  = wordvec_df.iloc[31962:,:]\n",
    "\n",
    "xtrain_w2v = train_w2v.iloc[ytrain.index,:]\n",
    "xvalid_w2v = train_w2v.iloc[yvalid.index,:]\n",
    "\n",
    "lreg.fit(xtrain_w2v, ytrain) \n",
    "\n",
    "prediction = lreg.predict_proba(xvalid_w2v)\n",
    "\n",
    "prediction_int = prediction[:,1] >= 0.3\n",
    "prediction_int = prediction_int.astype(np.int)\n",
    "\n",
    "f1_score(yvalid, prediction_int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Word2Vec Features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tfidf = tfidf[:11916,:]\n",
    "test_tfidf  = tfidf[11916:,:] \n",
    "\n",
    "xtrain_tfidf = train_tfidf[y_train.index]\n",
    "xvalid_tfidf = train_tfidf[yvalid.index]\n",
    "\n",
    "lreg.fit(xtrain_tfidf, ytrain) \n",
    "\n",
    "prediction = lreg.predict_proba(xvalid_tfidf)\n",
    "\n",
    "prediction_int = prediction[:,1] >= 0.3\n",
    "prediction_int = prediction_int.astype(np.int) \n",
    "\n",
    "f1_score(yvalidation, prediction_int) # calculating f1 score for the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "13240*0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Features de TF-IDF**\n",
    "\n",
    "Seguiremos as mesmas etapas acima, mas agora para o conjunto de recursos TF-IDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "# submission = test[['id','subtask_a']]\n",
    "# submission.to_csv('sub_lreg_bow.csv', index=False) # writing data to a CSV file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gerar arquivo de submissão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=pd.DataFrame()\n",
    "test_pred_int = test_pred[:,1] >= 0.3\n",
    "test_pred_int = test_pred_int.astype(np.int)\n",
    "test['subtask_a'] = test_pred_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_corpus = []\n",
    "for i in range(0, len(train)):\n",
    "    review = re.sub('[^a-zA-Z]', ' ', train['tidy_tweet'][i])\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "  \n",
    "    ps = PorterStemmer()\n",
    "  \n",
    "    # stemming\n",
    "    review = [ps.stem(word) for word in review]\n",
    "  \n",
    "    # joining them back with space\n",
    "    review = ' '.join(review)\n",
    "    train_corpus.append(review)\n",
    "    \n",
    "    \n",
    "test_corpus = []\n",
    "for i in range(11916, len(df_dados)):\n",
    "    review = re.sub('[^a-zA-Z]', ' ', test['tidy_tweet'][i])\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "  \n",
    "    ps = PorterStemmer()\n",
    "  \n",
    "    # stemming\n",
    "    review = [ps.stem(word) for word in review]\n",
    "  \n",
    "    # joining them back with space\n",
    "    review = ' '.join(review)\n",
    "    test_corpus.append(review)\n",
    "    \n",
    "    \n",
    "# creating bag of words do conjunto de treinamento\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(max_features = 1000)\n",
    "x = cv.fit_transform(train_corpus).toarray()\n",
    "y = train.iloc[:, 2]\n",
    "\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "\n",
    "\n",
    "# creating bag of words do conjunto de teste\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(max_features = 1000)\n",
    "x_test = cv.fit_transform(test_corpus).toarray()\n",
    "\n",
    "print(x_test.shape)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "lreg = LogisticRegression(solver='lbfgs') \n",
    "lreg.fit(x_train, y_train) \n",
    "\n",
    "prediction_b     = lreg.predict_proba(bow2_b) # predicting on the validation set \n",
    "prediction_int_b = prediction[:,1] >= 0.33         # if prediction is greater than or equal to 0.3 than 1 else 0 \n",
    "prediction_int_b = prediction_int.astype(np.int) \n",
    "prediction_int_b.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_corpus = []\n",
    "for i in range(0, len(train)):\n",
    "    review = re.sub('[^a-zA-Z]', ' ', train['tidy_tweet'][i])\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "  \n",
    "    ps = PorterStemmer()\n",
    "  \n",
    "    # stemming\n",
    "    review = [ps.stem(word) for word in review]\n",
    "  \n",
    "    # joining them back with space\n",
    "    review = ' '.join(review)\n",
    "    train_corpus.append(review)\n",
    "    \n",
    "    \n",
    "test_corpus = []\n",
    "for i in range(11916, len(df_dados)):\n",
    "    review = re.sub('[^a-zA-Z]', ' ', test['tidy_tweet'][i])\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "  \n",
    "    ps = PorterStemmer()\n",
    "  \n",
    "    # stemming\n",
    "    review = [ps.stem(word) for word in review]\n",
    "  \n",
    "    # joining them back with space\n",
    "    review = ' '.join(review)\n",
    "    test_corpus.append(review)\n",
    "    \n",
    "    \n",
    "# creating bag of words do conjunto de treinamento\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(max_features = 1000)\n",
    "x = cv.fit_transform(train_corpus).toarray()\n",
    "y = train.iloc[:, 2]\n",
    "\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "\n",
    "\n",
    "# creating bag of words do conjunto de teste\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(max_features = 1000)\n",
    "x_test = cv.fit_transform(test_corpus).toarray()\n",
    "\n",
    "print(x_test.shape)\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "lreg = LogisticRegression(solver='lbfgs') \n",
    "lreg.fit(x_train, y_train) \n",
    "\n",
    "prediction_a     = lreg.predict_proba(bow_a) # predicting on the validation set \n",
    "prediction_int_a = prediction[:,1] >= 0.33         # if prediction is greater than or equal to 0.3 than 1 else 0 \n",
    "prediction_int_a = prediction_int.astype(np.int) \n",
    "prediction_int_a.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LogisticRegression task_a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilizar o modelo para predição de classes do Held-Out-Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow2_b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow2vec_heldb = CountVectorizer(max_df=0.90, min_df=2, max_features=1000, stop_words='english')\n",
    "bow2_b = bowvec_heldb.fit_transform(bow2)\n",
    "bow2_b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "print('Calculando Bag of Words...')\n",
    "start0 = time.time()\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(ngram_range=(1,2))\n",
    "text_counts = cv.fit_transform(heldout_b['tidy_tweet'])\n",
    "text_counts.toarray()\n",
    "cv.get_feature_names()\n",
    "\n",
    "bow2 = pd.DataFrame(text_counts.toarray(), columns=cv.get_feature_names())\n",
    "bow2\n",
    "\n",
    "end0 = time.time()\n",
    "dur0 = np.round(end0-start0,2)\n",
    "print('-'*80)\n",
    "print('BoW de bigramas para',len(bow2),'Tweets gerado em',dur0,'segundos. Forma:',bow2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "X, y = make_classification(n_samples=260, n_features=2, n_informative=2,\n",
    "                           n_redundant=0, n_repeated=0, n_classes=3,\n",
    "                           n_clusters_per_class=1,\n",
    "                           weights=[0.01, 0.05, 0.94],\n",
    "                           class_sep=0.8, random_state=0)\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "ros = RandomOverSampler(random_state=0)\n",
    "X_resampled, y_resampled = ros.fit_resample(X, y)\n",
    "\n",
    "from collections import Counter\n",
    "print(sorted(Counter(y_resampled).items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xb = heldout_b['tidy_tweet']\n",
    "print(len(Xb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heldout_b.index = heldout_b.id\n",
    "heldout_b.drop(['id','tweet'], axis=1, inplace= True)\n",
    "heldout_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare(heldout_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heldout_b = pd.read_csv('datasets/testset-levelb.tsv', sep='\\t', usecols=('id','tweet'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Held Out Data - level_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bow_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bowvec_helda = CountVectorizer(max_df=0.90, min_df=2, max_features=1000, stop_words='english')\n",
    "\n",
    "bow_a = bowvec_helda.fit_transform(heldout_a['tidy_tweet'])\n",
    "bow_a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amostra=0.2\n",
    "train_bow2 = bow[:9930,:]\n",
    "train_bow2\n",
    "\n",
    "test_bow2 = bow[9930:,:]\n",
    "test_bow2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(prediction_intb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "lreg = LogisticRegression(solver='lbfgs') \n",
    "lreg.fit(x_train, y_train) \n",
    "\n",
    "predictionb     = lreg.predict_proba(bow2_b) # predicting on the validation set \n",
    "prediction_intb = prediction_int.astype(np.int)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  now to create a PANDAS data frame\n",
    "df = pd.DataFrame(data = FF_maxRSSBasal, columns=['FF_maxRSSBasal'])\n",
    "\n",
    "# from here on, we use the trick of creating a new dataframe and then \"add\"ing it\n",
    "df2 = pd.DataFrame(data = FF_maxRSSPrism, columns=['FF_maxRSSPrism'])\n",
    "df = df.add( df2, fill_value=0 )\n",
    "df2 = pd.DataFrame(data = FF_maxRSSPyramidal, columns=['FF_maxRSSPyramidal'])\n",
    "df = df.add( df2, fill_value=0 )\n",
    "df2 = pd.DataFrame(data = deltaFF_strainE22, columns=['deltaFF_strainE22'])\n",
    "df = df.add( df2, fill_value=0 )\n",
    "df2 = pd.DataFrame(data = scaled, columns=['scaled'])\n",
    "df = df.add( df2, fill_value=0 )\n",
    "df2 = pd.DataFrame(data = deltaFF_orientation, columns=['deltaFF_orientation'])\n",
    "df = df.add( df2, fill_value=0 )\n",
    "#print(df)\n",
    "df.to_csv('FF_data_frame.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({'A': ['A0', 'A1', 'A2', 'A3'],\n",
    "                     'B': ['B0', 'B1', 'B2', 'B3']})\n",
    "\n",
    "\n",
    "df2 = pd.DataFrame({'C': ['C0', 'C1'],\n",
    "                      'D': ['D0', 'D1']})\n",
    "\n",
    "df1['k'] = 1\n",
    "df2['k'] = 1\n",
    "\n",
    "resultado = pd.merge(df1, df2, on=['k'])\n",
    "\n",
    "resultado = resultado.drop([\"k\"], axis=1)\n",
    "print(resultado.head(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_a.add(pd.Series(y_pred), fill_value=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
